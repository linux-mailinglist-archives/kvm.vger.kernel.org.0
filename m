Return-Path: <kvm-owner@vger.kernel.org>
X-Original-To: lists+kvm@lfdr.de
Delivered-To: lists+kvm@lfdr.de
Received: from vger.kernel.org (vger.kernel.org [23.128.96.18])
	by mail.lfdr.de (Postfix) with ESMTP id 131A04298D4
	for <lists+kvm@lfdr.de>; Mon, 11 Oct 2021 23:26:11 +0200 (CEST)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S235264AbhJKV2K (ORCPT <rfc822;lists+kvm@lfdr.de>);
        Mon, 11 Oct 2021 17:28:10 -0400
Received: from lindbergh.monkeyblade.net ([23.128.96.19]:55342 "EHLO
        lindbergh.monkeyblade.net" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S235270AbhJKV2J (ORCPT <rfc822;kvm@vger.kernel.org>);
        Mon, 11 Oct 2021 17:28:09 -0400
Received: from mail-lf1-x133.google.com (mail-lf1-x133.google.com [IPv6:2a00:1450:4864:20::133])
        by lindbergh.monkeyblade.net (Postfix) with ESMTPS id C5299C06161C
        for <kvm@vger.kernel.org>; Mon, 11 Oct 2021 14:26:08 -0700 (PDT)
Received: by mail-lf1-x133.google.com with SMTP id y26so79685759lfa.11
        for <kvm@vger.kernel.org>; Mon, 11 Oct 2021 14:26:08 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20210112;
        h=mime-version:references:in-reply-to:from:date:message-id:subject:to
         :cc;
        bh=xcRWxDlAfrimSE84VLnmpWgRqiwYeCndtw1o8O6UyWE=;
        b=M8rn6rE11Xe0V/b41+T7DPd1w/MsbdChU4RsgVfES8UAJauiskbXQfjGsrwUBdfQ3+
         SRjkP3zfGBH4hPy3qTLulYe2YbF1bxjjmljQD8Z4lvXHaRlgOwKKH6TqtokjxFyJiaiY
         FgvE+0ahrM6cc0WR4isuplf2+9R4Ehf811nmFjg6sP1v+AJN6HPYRBNgWXYY/Ao3YTz4
         +TCLQ9jr8AoacmCRHbgBKh5B0VvDHOq9qYVULKxEjgI9LHg14S5cg/5b9RVjgNRDqPm0
         pBZ7zEmhqgUNnLdpMyJhdg9g5iEicr3pJt+CoS/JIfivgvSB/Af8Z9XMuEXRSdzTur9S
         Dzvw==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20210112;
        h=x-gm-message-state:mime-version:references:in-reply-to:from:date
         :message-id:subject:to:cc;
        bh=xcRWxDlAfrimSE84VLnmpWgRqiwYeCndtw1o8O6UyWE=;
        b=fI/2LszZJ9Mw531HMqcgTzbUYNbW83o8jByzt9gk1udf5S7CQ/X6ydiVaLpdFSdDWq
         ck5t1jK5v6g6kurJTB+QIreaqLzwGUU+t3qvKZgcxliFfLhU8MOhXw8pbiTlBKhFy7jJ
         X35THNmy9flkjVruT0PwdgfMZAgF1bt/2ihAcsUIKGmb9Pp5c6gCddNs+fAcsI0M/9dn
         3MuEYKK3B0jB1oLhjCL8x3N5e/Dz57No8634ITTehoThc9bpQpff67Mq1SnPCIUZba62
         0fmTG698u9E07Pf8mbDqKxfgaCOYJQ3hHrsnpkg1janzdxjDH80pXfa0S4viAqXmx7z0
         ptQQ==
X-Gm-Message-State: AOAM533DdGBEIm11pphTnbvfpk3BMrKq1sCX8XjqJOlFU2ewKUJSHZhd
        FmlcUp0JznwvgyfnfPrjspWHJmXgfb9MsTBfWagcSQ==
X-Google-Smtp-Source: ABdhPJyRK6qJtP+HVp1SayaW8JqhQ/BbVdQu9pj8SfSkvsgX/NJeUk7aR6gNbNIlclE6U/8BxY6bCam1SCnJy/tJFrE=
X-Received: by 2002:a2e:461a:: with SMTP id t26mr26029403lja.198.1633987566940;
 Mon, 11 Oct 2021 14:26:06 -0700 (PDT)
MIME-Version: 1.0
References: <20211011204418.162846-1-dmatlack@google.com> <CANgfPd9R5kv-URf2huH8NBmggrh_1wfa+ap=1QRWN4YdJHCXEQ@mail.gmail.com>
In-Reply-To: <CANgfPd9R5kv-URf2huH8NBmggrh_1wfa+ap=1QRWN4YdJHCXEQ@mail.gmail.com>
From:   David Matlack <dmatlack@google.com>
Date:   Mon, 11 Oct 2021 14:25:40 -0700
Message-ID: <CALzav=dXGFTTWtrZafc3K7ny66Kgz07DsTdVWneUen4io+k=_g@mail.gmail.com>
Subject: Re: [PATCH] KVM: x86/mmu: Rename slot_handle_leaf to slot_handle_level_4k
To:     Ben Gardon <bgardon@google.com>
Cc:     Paolo Bonzini <pbonzini@redhat.com>,
        kvm list <kvm@vger.kernel.org>,
        Sean Christopherson <seanjc@google.com>,
        Junaid Shahid <junaids@google.com>
Content-Type: text/plain; charset="UTF-8"
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

On Mon, Oct 11, 2021 at 2:07 PM Ben Gardon <bgardon@google.com> wrote:
>
> On Mon, Oct 11, 2021 at 1:44 PM David Matlack <dmatlack@google.com> wrote:
> >
> > slot_handle_leaf is a misnomer because it only operates on 4K SPTEs
> > whereas "leaf" is used to describe any valid terminal SPTE (4K or
> > large page). Rename slot_handle_leaf to slot_handle_level_4k to
> > avoid confusion.
> >
> > Making this change makes it more obvious there is a benign discrepency
> > between the legacy MMU and the TDP MMU when it comes to dirty logging.
> > The legacy MMU only operates on 4K SPTEs when zapping for collapsing
> > and when clearing D-bits. The TDP MMU, on the other hand, operates on
> > SPTEs on all levels. The TDP MMU behavior is technically overkill but
> > not incorrect. So opportunistically add comments to explain the
> > difference.
>
> Note that at least in the zapping case when disabling dirty logging,
> the TDP MMU will still only zap pages if they're mapped smaller than
> the highest granularity they could be. As a result it uses a slower
> check, but shouldn't be doing many (if any) extra zaps.

Agreed. The legacy MMU implementation relies on the fact that
collapsible 2M SPTEs are never generated by dirty logging so it only
needs to check 4K SPTEs.

The TDP MMU implementation is actually more robust, since it checks
every SPTE for collapsibility. The only reason it would be doing extra
zaps if there is something other than dirty logging can cause an SPTE
to be collapsible. (HugePage NX comes to mind.)

>
> >
> > Signed-off-by: David Matlack <dmatlack@google.com>
>
> Reviewed-by: Ben Gardon <bgardon@google.com>
>
> > ---
> >  arch/x86/kvm/mmu/mmu.c | 18 +++++++++++++-----
> >  1 file changed, 13 insertions(+), 5 deletions(-)
> >
> > diff --git a/arch/x86/kvm/mmu/mmu.c b/arch/x86/kvm/mmu/mmu.c
> > index 24a9f4c3f5e7..f00644e79ef5 100644
> > --- a/arch/x86/kvm/mmu/mmu.c
> > +++ b/arch/x86/kvm/mmu/mmu.c
> > @@ -5382,8 +5382,8 @@ slot_handle_level(struct kvm *kvm, const struct kvm_memory_slot *memslot,
> >  }
> >
> >  static __always_inline bool
> > -slot_handle_leaf(struct kvm *kvm, const struct kvm_memory_slot *memslot,
> > -                slot_level_handler fn, bool flush_on_yield)
> > +slot_handle_level_4k(struct kvm *kvm, const struct kvm_memory_slot *memslot,
> > +                    slot_level_handler fn, bool flush_on_yield)
> >  {
> >         return slot_handle_level(kvm, memslot, fn, PG_LEVEL_4K,
> >                                  PG_LEVEL_4K, flush_on_yield);
> > @@ -5772,7 +5772,12 @@ void kvm_mmu_zap_collapsible_sptes(struct kvm *kvm,
> >
> >         if (kvm_memslots_have_rmaps(kvm)) {
> >                 write_lock(&kvm->mmu_lock);
> > -               flush = slot_handle_leaf(kvm, slot, kvm_mmu_zap_collapsible_spte, true);
> > +               /*
> > +                * Strictly speaking only 4k SPTEs need to be zapped because
> > +                * KVM never creates intermediate 2m mappings when performing
> > +                * dirty logging.
> > +                */
> > +               flush = slot_handle_level_4k(kvm, slot, kvm_mmu_zap_collapsible_spte, true);
> >                 if (flush)
> >                         kvm_arch_flush_remote_tlbs_memslot(kvm, slot);
> >                 write_unlock(&kvm->mmu_lock);
> > @@ -5809,8 +5814,11 @@ void kvm_mmu_slot_leaf_clear_dirty(struct kvm *kvm,
> >
> >         if (kvm_memslots_have_rmaps(kvm)) {
> >                 write_lock(&kvm->mmu_lock);
> > -               flush = slot_handle_leaf(kvm, memslot, __rmap_clear_dirty,
> > -                                        false);
> > +               /*
> > +                * Strictly speaking only 4k SPTEs need to be cleared because
> > +                * KVM always performs dirty logging at a 4k granularity.
> > +                */
> > +               flush = slot_handle_level_4k(kvm, memslot, __rmap_clear_dirty, false);
> >                 write_unlock(&kvm->mmu_lock);
> >         }
> >
> > --
> > 2.33.0.882.g93a45727a2-goog
> >
